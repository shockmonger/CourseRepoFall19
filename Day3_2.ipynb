{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideally we should just show them how to use neural network for 1 classification task, and 1 regression task, then we will ask them to change size of the network (number of neurons and number of layers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these exercises, we will write a vanilla neural network to distinguish between kick and snare drum samples that we have in the data folder. First, we will write these for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.2\n"
     ]
    }
   ],
   "source": [
    "#import numpy\n",
    "import numpy as np\n",
    "\n",
    "#import librosa and display the library verion installed in yoru system\n",
    "import librosa, librosa.display\n",
    "print(librosa.__version__)\n",
    "\n",
    "#import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Render plots interactively in the notebook (not a must)\n",
    "#alternatively use matplotlib inline or matplotlib notebook or matplotlib nbagg\n",
    "%matplotlib inline\n",
    "\n",
    "#select a different color-scheme for the plots\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "\n",
    "#importing audio widget from IPython.display for audio playback\n",
    "from IPython.display import Audio\n",
    "\n",
    "#import scipy or scientific python\n",
    "import scipy\n",
    "\n",
    "#import os (helps retrieve the file names from the directory structure on your computer, and much more)\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "#iimport scikit-learn\n",
    "import sklearn\n",
    "\n",
    "#importing pandas for being able to load data from files such as comma separated values files\n",
    "import pandas as pd\n",
    "\n",
    "#import pathlib to easily write a function to work on all the files in a folder\n",
    "from pathlib import Path\n",
    "\n",
    "#importing scikit learn library for learning\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "For this exercise, we will be training a multi layer perceptron to classify snare and kick drum samples from the Data/drum_samples files.\n",
    "\n",
    "Multi-layer Perceptron (MLP) is a supervised learning algorithm that learns a function by training on a dataset, where is the number of dimensions for input and is the number of dimensions for output. Given a set of features and a target, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. Figure 1 shows a one hidden layer MLP with scalar output.\n",
    "../_images/multilayerperceptron_network.png\n",
    "\n",
    "Figure 1 : One hidden layer MLP.\n",
    "\n",
    "The leftmost layer, known as the input layer, consists of a set of neurons\n",
    "representing the input features. Each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation , followed by a non-linear activation function\n",
    "\n",
    "- like the hyperbolic tan function. The output layer receives the values from the last hidden layer and transforms them into output values.\n",
    "\n",
    "The module contains the public attributes coefs_ and intercepts_. coefs_ is a list of weight matrices, where weight matrix at index\n",
    "represents the weights between layer and layer . intercepts_ is a list of bias vectors, where the vector at index represents the bias values added to layer\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/multilayerperceptron_network.png\">\n",
    "\n",
    "The advantages of Multi-layer Perceptron are:\n",
    "\n",
    "        Capability to learn non-linear models.\n",
    "        Capability to learn models in real-time (on-line learning) using partial_fit.\n",
    "\n",
    "The disadvantages of Multi-layer Perceptron (MLP) include:\n",
    "\n",
    "        MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.\n",
    "        MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.\n",
    "        MLP is sensitive to feature scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset\n",
    "First, we need to have a dataset that we can train our model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n",
      "18\n",
      "18 18\n"
     ]
    }
   ],
   "source": [
    "#The next line of code includes an inline for loop \n",
    "#which will load all .mp3 samples starting with kick into kick_signals.\n",
    "#The * star is also called wildcard, the librosa.load will be performed on all files which name starts\n",
    "#with kick and ends with .wav (e.g. kick_03.wav, but also kick_adsugds.wav which we do not have in the folder).\n",
    "#Mind that the sampling rate is the default one (do you remember the value?).\n",
    "#The code below will actually create a LIST (squared brackets in Python) of Numpy arrays.\n",
    "#Te have to take this approach because we are not sure that if files have the same number of samples (they do not)\n",
    "#othrwise we could use a matrix (aka N dimensional Numpy array).\n",
    "kick_signals = [ librosa.load(p, mono=True)[0] for p in Path().glob('Data/drum_samples/kick*.wav') ]\n",
    "\n",
    "\n",
    "#Repeating the same for snare samples\n",
    "snare_signals = [ librosa.load(p, mono=True)[0] for p in Path().glob('Data/drum_samples/snare*.wav') ]\n",
    "\n",
    "#Repeating the same for \n",
    "cymbal_signals = [ librosa.load(p, mono=True)[0] for p in Path().glob('Data/drum_samples/cymbal*.wav')]\n",
    "\n",
    "#Printing the size (lenght, using len() ) of the lists which includes kick and snares (separately).\n",
    "#Does the number make sense versus what you have in the drum_samples folder?\n",
    "print(len(kick_signals))\n",
    "print(len(snare_signals))\n",
    "print(len(cymbal_signals))\n",
    "\n",
    "#Reduce the sizes of all signals to the max size of cymbal files>\n",
    "kick_signals = kick_signals[0:18]\n",
    "snare_signals = snare_signals[0:18]\n",
    "print(len(kick_signals),len(snare_signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Numpy arrays for kick and snare features:\n",
      "(18, 5) (18, 5) (18, 5)\n",
      "Size of labels array (54,)\n",
      "Size of feature array (54, 5)\n"
     ]
    }
   ],
   "source": [
    "#Instead of writing the code to extract the features we define a function,\n",
    "#which is more elegant, it's reusable (shorter code) and makes the following code more readable.\n",
    "#All features (5 of them) are from librosa and are all scalar (we take the mean over multiple blocks).\n",
    "#We have to do this (use average) because we did not check if all files have the same lenght (actually they are different).\n",
    "#Different file lenght generates Numpy arrays of different lenght (not comparable)\n",
    "#The function returns a list containing the mean of the features on \"signal\", which is the parameter we pass to the function\n",
    "#Mind that these features may not be the best to perform the classification task (it's just an example!)\n",
    "def extract_features(signal):\n",
    "\n",
    "    return [\n",
    "        np.mean(librosa.feature.zero_crossing_rate(signal)),\n",
    "        np.mean(librosa.feature.spectral_centroid(signal)),\n",
    "        np.mean(librosa.feature.spectral_contrast(signal)),\n",
    "        np.mean(librosa.feature.rmse(signal)),\n",
    "        np.mean(librosa.feature.spectral_flatness(signal)),\n",
    "    ]\n",
    "\n",
    "\n",
    "#Extracting our the 5 scalar features for all kick samples.\n",
    "#Ee are using another inline for loop (this is very convenient when working with lists).\n",
    "#Now we can store the data on an Numpy array because the size of the data is consistent,\n",
    "#indeed we will have 5 numbers (features) per sample\n",
    "#to be precise, we are still storing data into a list [], and then we use the function np.array\n",
    "#to convert the list into an array (we need Numpy arrays for our ML algorithm, not lists)\n",
    "kick_features = np.array([extract_features(x) for x in kick_signals])\n",
    "\n",
    "#Repearing the same for the snare samples.\n",
    "snare_features = np.array([extract_features(x) for x in snare_signals])\n",
    "\n",
    "#repeating the same for cymbal samples\n",
    "cymbal_features = np.array([extract_features(x) for x in cymbal_signals])\n",
    "\n",
    "#Displaying the size of the Numpy arrays (this time we use the .shape attribute)\n",
    "#Check if the printed numbers are the expected ones (what's on the rows and what's on the columns?)\n",
    "print('Size of Numpy arrays for kick and snare features:')\n",
    "print(kick_features.shape, snare_features.shape, cymbal_features.shape)\n",
    "\n",
    "#Now we create an array of labels, we can use zeros for the kicks and ones for the snare (or any other number).\n",
    "#This will help us to discriminate set of featires associated with kicks and snares\n",
    "#We can opt for \"text\" labels but this is not convenient,\n",
    "#It wont work well with neural networks, and we put \"text\" labels in Numpy arrays\n",
    "\n",
    "#Create a row of zeroes as long as the number of kick samples\n",
    "kicklabels = np.zeros(kick_features.shape[0])\n",
    "\n",
    "#Create a row of ones as long as the number of snare samples\n",
    "snarelabels = np.ones(snare_features.shape[0])\n",
    "\n",
    "#Create a row of twos as long as the number of cymbal samples\n",
    "cymballabels = np.full(len(cymbal_features),2)\n",
    "\n",
    "#Now we concatenate (attach) the numeric labels into a single array,\n",
    "#and we also concatenate the two set of features\n",
    "labels = np.concatenate((kicklabels,snarelabels,cymballabels))\n",
    "features = np.concatenate((kick_features,snare_features,cymbal_features))\n",
    "\n",
    "#check the output and reconsile these with what we just did\n",
    "print('Size of labels array',labels.shape)\n",
    "print('Size of feature array',features.shape)\n",
    "\n",
    "#Here we use the scale function of scikit-learn to scale the features,\n",
    "#this is important when using hetherogeneous (different) scalar features.\n",
    "#After this step all features will present zero mean and unit veriance (i.e. they are more comparable).\n",
    "#It is way less recommended to do this with vectorial features.\n",
    "#In this case we are overwiting the previous Numpy variable (or array) instead of creating a new one\n",
    "#(it is fine if you do not need the old data anymore, and it reduces the number of variables you use in a program)\n",
    "features = sklearn.preprocessing.scale(features)\n",
    "\n",
    "\n",
    "#Moving the data into a Pandas structure and we assign name to each column (features are on column)\n",
    "dataset = pd.DataFrame(features)\n",
    "dataset.columns = ['ZC','SpecCen','SpecCon','RMS','SpecFlat']\n",
    "\n",
    "#Sticking an extra colum as labels\n",
    "dataset['Label'] = labels\n",
    "\n",
    "#this will display the Pandas data structure\n",
    "dataset\n",
    "\n",
    "classes = ['kick','snare','cymbal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we train on only ONE feature in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data from first five columns of features to X variable\n",
    "X = dataset.iloc[:, 0:1]\n",
    "\n",
    "# Assign data from first fifth columns to y variable\n",
    "y = dataset.iloc[:,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the test train splitting from the model selection component from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use the train_test_split function to import the results to the following variables as the names suggest:\n",
    "#X_train and y_train will contain training data and labels, while\n",
    "#X_test and y_test will contain testing data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import the classifier for the network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Call the classifier and specify the size of layers\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(2, 2), max_iter=500)\n",
    "\n",
    "#Fit the mlp model to the training set\n",
    "mlp.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Store the predictions of the network in a variable called predictions\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [3 0 2]\n",
      " [0 0 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      1.00      0.73         4\n",
      "        1.0       0.00      0.00      0.00         5\n",
      "        2.0       0.50      1.00      0.67         2\n",
      "\n",
      "avg / total       0.30      0.55      0.39        11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "#Store the confusion matrix in the variable confMat\n",
    "confMat = confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the confusion matrix. Each block represents misclassified and correctly classified samples\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "im = ax.imshow(confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we see, the average precision is 80%, average recall and f1 score are both around barely 50%. We try again with 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 2 3]\n",
      " [0 0 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00         6\n",
      "        1.0       1.00      0.40      0.57         5\n",
      "        2.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.73      0.81        11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign data from first five columns of features to X variable\n",
    "X = dataset.iloc[:, 0:4]\n",
    "#NOTE> THIS IS WHERE WE ASSIGN FEATURES to the X variable\n",
    "\n",
    "\n",
    "# Assign data from first fifth columns to y variable\n",
    "y = dataset.iloc[:,5]\n",
    "\n",
    "\n",
    "#Import the test train splitting from the model selection component from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use the train_test_split function to import the results to the following variables as the names suggest:\n",
    "#X_train and y_train will contain training data and labels, while\n",
    "#X_test and y_test will contain testing data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n",
    "\n",
    "#Import the classifier for the network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Call the classifier and specify the size of layers\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(2,2), max_iter=500)\n",
    "\n",
    "#Fit the mlp model to the training set\n",
    "mlp.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Store the predictions of the network in a variable called predictions\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "#Store the confusion matrix in the variable confMat\n",
    "confMat = confusion_matrix(y_test,predictions)\n",
    "\n",
    "#Visualize the confusion matrix. Each block represents misclassified and correctly classified samples\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "im = ax.imshow(confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that the network somehow got worse even with the use of 4 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following code, we increase the network size even more, and also use many more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00         6\n",
      "        1.0       1.00      1.00      1.00         2\n",
      "        2.0       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00        11\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign data from first five columns of features to X variable\n",
    "X = dataset.iloc[:, 0:5]\n",
    "#NOTE> THIS IS WHERE WE ASSIGN FEATURES to the X variable\n",
    "\n",
    "\n",
    "# Assign data from first fifth columns to y variable\n",
    "y = dataset.iloc[:,5]\n",
    "\n",
    "\n",
    "#Import the test train splitting from the model selection component from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use the train_test_split function to import the results to the following variables as the names suggest:\n",
    "#X_train and y_train will contain training data and labels, while\n",
    "#X_test and y_test will contain testing data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n",
    "\n",
    "#Import the classifier for the network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Call the classifier and specify the size of layers\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "\n",
    "#Fit the mlp model to the training set\n",
    "mlp.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Store the predictions of the network in a variable called predictions\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "#Store the confusion matrix in the variable confMat\n",
    "confMat = confusion_matrix(y_test,predictions)\n",
    "\n",
    "#Visualize the confusion matrix. Each block represents misclassified and correctly classified samples\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "im = ax.imshow(confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1:\n",
    "### Experiment with learning rate\n",
    "<br> Figure out how changing the learning rate in the parameters of the MLPCLassifier will change how the network performs.\n",
    "\n",
    "### Stop condition\n",
    "<br> Currently, the network stops when it has completed a maximum number of iterations. What other learning strategies could be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "### Implement the same network with a four classes with a new set of sound files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sine Wave for Predictive Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = np.arange(0, 10, 0.0001);\n",
    "\n",
    "# Amplitude of the sine wave is sine of a variable like time\n",
    "amplitude = np.sin(time)\n",
    "\n",
    "print(len(amplitude))\n",
    "\n",
    "# Plot a sine wave using time and amplitude obtained for the sine wave\n",
    "plt.plot(time, amplitude)\n",
    "# Give a title for the sine wave plot\n",
    "plt.title('Sine wave')\n",
    "# Give x axis label for the sine wave plot\n",
    "plt.xlabel('Time')\n",
    "# Give y axis label for the sine wave plot\n",
    "plt.ylabel('Amplitude = sin(time)')\n",
    "plt.grid(True, which='both')\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.show()\n",
    "# Display the sine wave\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts = [np.random.randint(1,99800) for _ in range(1000)]\n",
    "sines = []\n",
    "for i in range(len(starts)):\n",
    "    amparray = amplitude[starts[i]:starts[i]+100]\n",
    "    sines.append(amparray)\n",
    "np.array(sines).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.032709</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.032909</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.033109</td>\n",
       "      <td>0.033209</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.033508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041603</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>0.041902</td>\n",
       "      <td>0.042002</td>\n",
       "      <td>0.042102</td>\n",
       "      <td>0.042202</td>\n",
       "      <td>0.042302</td>\n",
       "      <td>0.042402</td>\n",
       "      <td>0.042502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.813930</td>\n",
       "      <td>-0.813872</td>\n",
       "      <td>-0.813814</td>\n",
       "      <td>-0.813756</td>\n",
       "      <td>-0.813698</td>\n",
       "      <td>-0.813640</td>\n",
       "      <td>-0.813581</td>\n",
       "      <td>-0.813523</td>\n",
       "      <td>-0.813465</td>\n",
       "      <td>-0.813407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.808669</td>\n",
       "      <td>-0.808610</td>\n",
       "      <td>-0.808551</td>\n",
       "      <td>-0.808492</td>\n",
       "      <td>-0.808433</td>\n",
       "      <td>-0.808374</td>\n",
       "      <td>-0.808315</td>\n",
       "      <td>-0.808257</td>\n",
       "      <td>-0.808198</td>\n",
       "      <td>-0.808139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082683</td>\n",
       "      <td>0.082584</td>\n",
       "      <td>0.082484</td>\n",
       "      <td>0.082384</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>0.082185</td>\n",
       "      <td>0.082085</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.081886</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073711</td>\n",
       "      <td>0.073611</td>\n",
       "      <td>0.073512</td>\n",
       "      <td>0.073412</td>\n",
       "      <td>0.073312</td>\n",
       "      <td>0.073212</td>\n",
       "      <td>0.073113</td>\n",
       "      <td>0.073013</td>\n",
       "      <td>0.072913</td>\n",
       "      <td>0.072813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.932512</td>\n",
       "      <td>-0.932548</td>\n",
       "      <td>-0.932584</td>\n",
       "      <td>-0.932620</td>\n",
       "      <td>-0.932656</td>\n",
       "      <td>-0.932692</td>\n",
       "      <td>-0.932729</td>\n",
       "      <td>-0.932765</td>\n",
       "      <td>-0.932801</td>\n",
       "      <td>-0.932837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.935724</td>\n",
       "      <td>-0.935760</td>\n",
       "      <td>-0.935795</td>\n",
       "      <td>-0.935830</td>\n",
       "      <td>-0.935865</td>\n",
       "      <td>-0.935901</td>\n",
       "      <td>-0.935936</td>\n",
       "      <td>-0.935971</td>\n",
       "      <td>-0.936006</td>\n",
       "      <td>-0.936042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.996140</td>\n",
       "      <td>0.996148</td>\n",
       "      <td>0.996157</td>\n",
       "      <td>0.996166</td>\n",
       "      <td>0.996175</td>\n",
       "      <td>0.996183</td>\n",
       "      <td>0.996192</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>0.996218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996889</td>\n",
       "      <td>0.996897</td>\n",
       "      <td>0.996905</td>\n",
       "      <td>0.996913</td>\n",
       "      <td>0.996921</td>\n",
       "      <td>0.996929</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>0.996944</td>\n",
       "      <td>0.996952</td>\n",
       "      <td>0.996960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031110</td>\n",
       "      <td>0.031210</td>\n",
       "      <td>0.031310</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>0.031509</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.031709</td>\n",
       "      <td>0.031809</td>\n",
       "      <td>0.031909</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040104</td>\n",
       "      <td>0.040204</td>\n",
       "      <td>0.040304</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.040504</td>\n",
       "      <td>0.040604</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.040803</td>\n",
       "      <td>0.040903</td>\n",
       "      <td>0.041003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.176056</td>\n",
       "      <td>0.175957</td>\n",
       "      <td>0.175859</td>\n",
       "      <td>0.175760</td>\n",
       "      <td>0.175662</td>\n",
       "      <td>0.175563</td>\n",
       "      <td>0.175465</td>\n",
       "      <td>0.175366</td>\n",
       "      <td>0.175268</td>\n",
       "      <td>0.175170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167189</td>\n",
       "      <td>0.167091</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.166893</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.166696</td>\n",
       "      <td>0.166598</td>\n",
       "      <td>0.166499</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.166302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.533472</td>\n",
       "      <td>0.533556</td>\n",
       "      <td>0.533641</td>\n",
       "      <td>0.533726</td>\n",
       "      <td>0.533810</td>\n",
       "      <td>0.533895</td>\n",
       "      <td>0.533979</td>\n",
       "      <td>0.534064</td>\n",
       "      <td>0.534148</td>\n",
       "      <td>0.534233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541062</td>\n",
       "      <td>0.541147</td>\n",
       "      <td>0.541231</td>\n",
       "      <td>0.541315</td>\n",
       "      <td>0.541399</td>\n",
       "      <td>0.541483</td>\n",
       "      <td>0.541567</td>\n",
       "      <td>0.541651</td>\n",
       "      <td>0.541735</td>\n",
       "      <td>0.541819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.690659</td>\n",
       "      <td>0.690731</td>\n",
       "      <td>0.690804</td>\n",
       "      <td>0.690876</td>\n",
       "      <td>0.690948</td>\n",
       "      <td>0.691021</td>\n",
       "      <td>0.691093</td>\n",
       "      <td>0.691165</td>\n",
       "      <td>0.691237</td>\n",
       "      <td>0.691310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697140</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>0.697283</td>\n",
       "      <td>0.697355</td>\n",
       "      <td>0.697426</td>\n",
       "      <td>0.697498</td>\n",
       "      <td>0.697570</td>\n",
       "      <td>0.697641</td>\n",
       "      <td>0.697713</td>\n",
       "      <td>0.697785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.733796</td>\n",
       "      <td>0.733728</td>\n",
       "      <td>0.733660</td>\n",
       "      <td>0.733592</td>\n",
       "      <td>0.733524</td>\n",
       "      <td>0.733456</td>\n",
       "      <td>0.733388</td>\n",
       "      <td>0.733320</td>\n",
       "      <td>0.733252</td>\n",
       "      <td>0.733184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727652</td>\n",
       "      <td>0.727583</td>\n",
       "      <td>0.727515</td>\n",
       "      <td>0.727446</td>\n",
       "      <td>0.727378</td>\n",
       "      <td>0.727309</td>\n",
       "      <td>0.727240</td>\n",
       "      <td>0.727172</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>0.727034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.560935</td>\n",
       "      <td>0.561018</td>\n",
       "      <td>0.561100</td>\n",
       "      <td>0.561183</td>\n",
       "      <td>0.561266</td>\n",
       "      <td>0.561349</td>\n",
       "      <td>0.561432</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.561597</td>\n",
       "      <td>0.561680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.568445</td>\n",
       "      <td>0.568527</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.568692</td>\n",
       "      <td>0.568774</td>\n",
       "      <td>0.568856</td>\n",
       "      <td>0.568939</td>\n",
       "      <td>0.569021</td>\n",
       "      <td>0.569103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.633132</td>\n",
       "      <td>0.633054</td>\n",
       "      <td>0.632977</td>\n",
       "      <td>0.632900</td>\n",
       "      <td>0.632822</td>\n",
       "      <td>0.632745</td>\n",
       "      <td>0.632667</td>\n",
       "      <td>0.632590</td>\n",
       "      <td>0.632512</td>\n",
       "      <td>0.632435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626140</td>\n",
       "      <td>0.626062</td>\n",
       "      <td>0.625984</td>\n",
       "      <td>0.625906</td>\n",
       "      <td>0.625828</td>\n",
       "      <td>0.625750</td>\n",
       "      <td>0.625672</td>\n",
       "      <td>0.625594</td>\n",
       "      <td>0.625516</td>\n",
       "      <td>0.625438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.842269</td>\n",
       "      <td>0.842215</td>\n",
       "      <td>0.842161</td>\n",
       "      <td>0.842107</td>\n",
       "      <td>0.842053</td>\n",
       "      <td>0.841999</td>\n",
       "      <td>0.841945</td>\n",
       "      <td>0.841891</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>0.841783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837383</td>\n",
       "      <td>0.837328</td>\n",
       "      <td>0.837274</td>\n",
       "      <td>0.837219</td>\n",
       "      <td>0.837164</td>\n",
       "      <td>0.837110</td>\n",
       "      <td>0.837055</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>0.836945</td>\n",
       "      <td>0.836891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.121286</td>\n",
       "      <td>-0.121187</td>\n",
       "      <td>-0.121087</td>\n",
       "      <td>-0.120988</td>\n",
       "      <td>-0.120889</td>\n",
       "      <td>-0.120790</td>\n",
       "      <td>-0.120690</td>\n",
       "      <td>-0.120591</td>\n",
       "      <td>-0.120492</td>\n",
       "      <td>-0.120393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112348</td>\n",
       "      <td>-0.112248</td>\n",
       "      <td>-0.112149</td>\n",
       "      <td>-0.112050</td>\n",
       "      <td>-0.111950</td>\n",
       "      <td>-0.111851</td>\n",
       "      <td>-0.111751</td>\n",
       "      <td>-0.111652</td>\n",
       "      <td>-0.111553</td>\n",
       "      <td>-0.111453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.830764</td>\n",
       "      <td>0.830708</td>\n",
       "      <td>0.830652</td>\n",
       "      <td>0.830596</td>\n",
       "      <td>0.830541</td>\n",
       "      <td>0.830485</td>\n",
       "      <td>0.830429</td>\n",
       "      <td>0.830374</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.830262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825720</td>\n",
       "      <td>0.825664</td>\n",
       "      <td>0.825607</td>\n",
       "      <td>0.825551</td>\n",
       "      <td>0.825495</td>\n",
       "      <td>0.825438</td>\n",
       "      <td>0.825382</td>\n",
       "      <td>0.825325</td>\n",
       "      <td>0.825269</td>\n",
       "      <td>0.825212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.825390</td>\n",
       "      <td>0.825334</td>\n",
       "      <td>0.825277</td>\n",
       "      <td>0.825221</td>\n",
       "      <td>0.825164</td>\n",
       "      <td>0.825108</td>\n",
       "      <td>0.825051</td>\n",
       "      <td>0.824995</td>\n",
       "      <td>0.824938</td>\n",
       "      <td>0.824882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820276</td>\n",
       "      <td>0.820218</td>\n",
       "      <td>0.820161</td>\n",
       "      <td>0.820104</td>\n",
       "      <td>0.820047</td>\n",
       "      <td>0.819989</td>\n",
       "      <td>0.819932</td>\n",
       "      <td>0.819875</td>\n",
       "      <td>0.819818</td>\n",
       "      <td>0.819760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.261530</td>\n",
       "      <td>-0.261627</td>\n",
       "      <td>-0.261723</td>\n",
       "      <td>-0.261820</td>\n",
       "      <td>-0.261916</td>\n",
       "      <td>-0.262013</td>\n",
       "      <td>-0.262109</td>\n",
       "      <td>-0.262206</td>\n",
       "      <td>-0.262302</td>\n",
       "      <td>-0.262399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270206</td>\n",
       "      <td>-0.270303</td>\n",
       "      <td>-0.270399</td>\n",
       "      <td>-0.270495</td>\n",
       "      <td>-0.270591</td>\n",
       "      <td>-0.270688</td>\n",
       "      <td>-0.270784</td>\n",
       "      <td>-0.270880</td>\n",
       "      <td>-0.270977</td>\n",
       "      <td>-0.271073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-0.998061</td>\n",
       "      <td>-0.998067</td>\n",
       "      <td>-0.998073</td>\n",
       "      <td>-0.998079</td>\n",
       "      <td>-0.998085</td>\n",
       "      <td>-0.998092</td>\n",
       "      <td>-0.998098</td>\n",
       "      <td>-0.998104</td>\n",
       "      <td>-0.998110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.998575</td>\n",
       "      <td>-0.998580</td>\n",
       "      <td>-0.998586</td>\n",
       "      <td>-0.998591</td>\n",
       "      <td>-0.998596</td>\n",
       "      <td>-0.998602</td>\n",
       "      <td>-0.998607</td>\n",
       "      <td>-0.998612</td>\n",
       "      <td>-0.998618</td>\n",
       "      <td>-0.998623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.722897</td>\n",
       "      <td>-0.722827</td>\n",
       "      <td>-0.722758</td>\n",
       "      <td>-0.722689</td>\n",
       "      <td>-0.722620</td>\n",
       "      <td>-0.722551</td>\n",
       "      <td>-0.722482</td>\n",
       "      <td>-0.722413</td>\n",
       "      <td>-0.722344</td>\n",
       "      <td>-0.722274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.716649</td>\n",
       "      <td>-0.716579</td>\n",
       "      <td>-0.716509</td>\n",
       "      <td>-0.716440</td>\n",
       "      <td>-0.716370</td>\n",
       "      <td>-0.716300</td>\n",
       "      <td>-0.716230</td>\n",
       "      <td>-0.716160</td>\n",
       "      <td>-0.716091</td>\n",
       "      <td>-0.716021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.490009</td>\n",
       "      <td>0.490096</td>\n",
       "      <td>0.490183</td>\n",
       "      <td>0.490270</td>\n",
       "      <td>0.490358</td>\n",
       "      <td>0.490445</td>\n",
       "      <td>0.490532</td>\n",
       "      <td>0.490619</td>\n",
       "      <td>0.490706</td>\n",
       "      <td>0.490793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497834</td>\n",
       "      <td>0.497921</td>\n",
       "      <td>0.498008</td>\n",
       "      <td>0.498095</td>\n",
       "      <td>0.498181</td>\n",
       "      <td>0.498268</td>\n",
       "      <td>0.498355</td>\n",
       "      <td>0.498441</td>\n",
       "      <td>0.498528</td>\n",
       "      <td>0.498615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.861683</td>\n",
       "      <td>0.861633</td>\n",
       "      <td>0.861582</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.861480</td>\n",
       "      <td>0.861430</td>\n",
       "      <td>0.861379</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>0.861277</td>\n",
       "      <td>0.861226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857082</td>\n",
       "      <td>0.857030</td>\n",
       "      <td>0.856979</td>\n",
       "      <td>0.856927</td>\n",
       "      <td>0.856875</td>\n",
       "      <td>0.856824</td>\n",
       "      <td>0.856772</td>\n",
       "      <td>0.856721</td>\n",
       "      <td>0.856669</td>\n",
       "      <td>0.856618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.445471</td>\n",
       "      <td>0.445560</td>\n",
       "      <td>0.445650</td>\n",
       "      <td>0.445739</td>\n",
       "      <td>0.445829</td>\n",
       "      <td>0.445918</td>\n",
       "      <td>0.446008</td>\n",
       "      <td>0.446097</td>\n",
       "      <td>0.446187</td>\n",
       "      <td>0.446276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453510</td>\n",
       "      <td>0.453599</td>\n",
       "      <td>0.453689</td>\n",
       "      <td>0.453778</td>\n",
       "      <td>0.453867</td>\n",
       "      <td>0.453956</td>\n",
       "      <td>0.454045</td>\n",
       "      <td>0.454134</td>\n",
       "      <td>0.454223</td>\n",
       "      <td>0.454312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.954470</td>\n",
       "      <td>0.954440</td>\n",
       "      <td>0.954410</td>\n",
       "      <td>0.954380</td>\n",
       "      <td>0.954351</td>\n",
       "      <td>0.954321</td>\n",
       "      <td>0.954291</td>\n",
       "      <td>0.954261</td>\n",
       "      <td>0.954231</td>\n",
       "      <td>0.954201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951747</td>\n",
       "      <td>0.951716</td>\n",
       "      <td>0.951685</td>\n",
       "      <td>0.951654</td>\n",
       "      <td>0.951624</td>\n",
       "      <td>0.951593</td>\n",
       "      <td>0.951562</td>\n",
       "      <td>0.951532</td>\n",
       "      <td>0.951501</td>\n",
       "      <td>0.951470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.083824</td>\n",
       "      <td>-0.083923</td>\n",
       "      <td>-0.084023</td>\n",
       "      <td>-0.084123</td>\n",
       "      <td>-0.084222</td>\n",
       "      <td>-0.084322</td>\n",
       "      <td>-0.084421</td>\n",
       "      <td>-0.084521</td>\n",
       "      <td>-0.084621</td>\n",
       "      <td>-0.084720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092788</td>\n",
       "      <td>-0.092888</td>\n",
       "      <td>-0.092988</td>\n",
       "      <td>-0.093087</td>\n",
       "      <td>-0.093187</td>\n",
       "      <td>-0.093286</td>\n",
       "      <td>-0.093386</td>\n",
       "      <td>-0.093485</td>\n",
       "      <td>-0.093585</td>\n",
       "      <td>-0.093684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.362654</td>\n",
       "      <td>0.362748</td>\n",
       "      <td>0.362841</td>\n",
       "      <td>0.362934</td>\n",
       "      <td>0.363027</td>\n",
       "      <td>0.363120</td>\n",
       "      <td>0.363214</td>\n",
       "      <td>0.363307</td>\n",
       "      <td>0.363400</td>\n",
       "      <td>0.363493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371027</td>\n",
       "      <td>0.371120</td>\n",
       "      <td>0.371213</td>\n",
       "      <td>0.371306</td>\n",
       "      <td>0.371398</td>\n",
       "      <td>0.371491</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.371677</td>\n",
       "      <td>0.371770</td>\n",
       "      <td>0.371863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.138149</td>\n",
       "      <td>0.138050</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>0.137852</td>\n",
       "      <td>0.137753</td>\n",
       "      <td>0.137654</td>\n",
       "      <td>0.137555</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>0.137357</td>\n",
       "      <td>0.137258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129230</td>\n",
       "      <td>0.129131</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.128933</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>0.128734</td>\n",
       "      <td>0.128635</td>\n",
       "      <td>0.128536</td>\n",
       "      <td>0.128437</td>\n",
       "      <td>0.128338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.402549</td>\n",
       "      <td>0.402641</td>\n",
       "      <td>0.402732</td>\n",
       "      <td>0.402824</td>\n",
       "      <td>0.402915</td>\n",
       "      <td>0.403007</td>\n",
       "      <td>0.403098</td>\n",
       "      <td>0.403190</td>\n",
       "      <td>0.403281</td>\n",
       "      <td>0.403373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410771</td>\n",
       "      <td>0.410863</td>\n",
       "      <td>0.410954</td>\n",
       "      <td>0.411045</td>\n",
       "      <td>0.411136</td>\n",
       "      <td>0.411227</td>\n",
       "      <td>0.411318</td>\n",
       "      <td>0.411410</td>\n",
       "      <td>0.411501</td>\n",
       "      <td>0.411592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.509172</td>\n",
       "      <td>-0.509258</td>\n",
       "      <td>-0.509344</td>\n",
       "      <td>-0.509430</td>\n",
       "      <td>-0.509516</td>\n",
       "      <td>-0.509602</td>\n",
       "      <td>-0.509688</td>\n",
       "      <td>-0.509774</td>\n",
       "      <td>-0.509860</td>\n",
       "      <td>-0.509946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516897</td>\n",
       "      <td>-0.516982</td>\n",
       "      <td>-0.517068</td>\n",
       "      <td>-0.517154</td>\n",
       "      <td>-0.517239</td>\n",
       "      <td>-0.517325</td>\n",
       "      <td>-0.517410</td>\n",
       "      <td>-0.517496</td>\n",
       "      <td>-0.517582</td>\n",
       "      <td>-0.517667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.373598</td>\n",
       "      <td>-0.373506</td>\n",
       "      <td>-0.373413</td>\n",
       "      <td>-0.373320</td>\n",
       "      <td>-0.373227</td>\n",
       "      <td>-0.373135</td>\n",
       "      <td>-0.373042</td>\n",
       "      <td>-0.372949</td>\n",
       "      <td>-0.372856</td>\n",
       "      <td>-0.372763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365235</td>\n",
       "      <td>-0.365142</td>\n",
       "      <td>-0.365049</td>\n",
       "      <td>-0.364956</td>\n",
       "      <td>-0.364863</td>\n",
       "      <td>-0.364770</td>\n",
       "      <td>-0.364676</td>\n",
       "      <td>-0.364583</td>\n",
       "      <td>-0.364490</td>\n",
       "      <td>-0.364397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.921717</td>\n",
       "      <td>-0.921679</td>\n",
       "      <td>-0.921640</td>\n",
       "      <td>-0.921601</td>\n",
       "      <td>-0.921562</td>\n",
       "      <td>-0.921523</td>\n",
       "      <td>-0.921485</td>\n",
       "      <td>-0.921446</td>\n",
       "      <td>-0.921407</td>\n",
       "      <td>-0.921368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918189</td>\n",
       "      <td>-0.918150</td>\n",
       "      <td>-0.918110</td>\n",
       "      <td>-0.918070</td>\n",
       "      <td>-0.918031</td>\n",
       "      <td>-0.917991</td>\n",
       "      <td>-0.917952</td>\n",
       "      <td>-0.917912</td>\n",
       "      <td>-0.917872</td>\n",
       "      <td>-0.917832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.753834</td>\n",
       "      <td>0.753768</td>\n",
       "      <td>0.753703</td>\n",
       "      <td>0.753637</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.753506</td>\n",
       "      <td>0.753440</td>\n",
       "      <td>0.753374</td>\n",
       "      <td>0.753308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747956</td>\n",
       "      <td>0.747890</td>\n",
       "      <td>0.747824</td>\n",
       "      <td>0.747757</td>\n",
       "      <td>0.747691</td>\n",
       "      <td>0.747625</td>\n",
       "      <td>0.747558</td>\n",
       "      <td>0.747492</td>\n",
       "      <td>0.747425</td>\n",
       "      <td>0.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.881712</td>\n",
       "      <td>0.881664</td>\n",
       "      <td>0.881617</td>\n",
       "      <td>0.881570</td>\n",
       "      <td>0.881523</td>\n",
       "      <td>0.881476</td>\n",
       "      <td>0.881428</td>\n",
       "      <td>0.881381</td>\n",
       "      <td>0.881334</td>\n",
       "      <td>0.881287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877430</td>\n",
       "      <td>0.877382</td>\n",
       "      <td>0.877334</td>\n",
       "      <td>0.877286</td>\n",
       "      <td>0.877238</td>\n",
       "      <td>0.877190</td>\n",
       "      <td>0.877142</td>\n",
       "      <td>0.877094</td>\n",
       "      <td>0.877046</td>\n",
       "      <td>0.876998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>-0.988121</td>\n",
       "      <td>-0.988136</td>\n",
       "      <td>-0.988152</td>\n",
       "      <td>-0.988167</td>\n",
       "      <td>-0.988182</td>\n",
       "      <td>-0.988198</td>\n",
       "      <td>-0.988213</td>\n",
       "      <td>-0.988228</td>\n",
       "      <td>-0.988244</td>\n",
       "      <td>-0.988259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.989464</td>\n",
       "      <td>-0.989479</td>\n",
       "      <td>-0.989493</td>\n",
       "      <td>-0.989507</td>\n",
       "      <td>-0.989522</td>\n",
       "      <td>-0.989536</td>\n",
       "      <td>-0.989551</td>\n",
       "      <td>-0.989565</td>\n",
       "      <td>-0.989580</td>\n",
       "      <td>-0.989594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>-0.964379</td>\n",
       "      <td>-0.964352</td>\n",
       "      <td>-0.964326</td>\n",
       "      <td>-0.964300</td>\n",
       "      <td>-0.964273</td>\n",
       "      <td>-0.964247</td>\n",
       "      <td>-0.964220</td>\n",
       "      <td>-0.964194</td>\n",
       "      <td>-0.964167</td>\n",
       "      <td>-0.964140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.961959</td>\n",
       "      <td>-0.961932</td>\n",
       "      <td>-0.961905</td>\n",
       "      <td>-0.961877</td>\n",
       "      <td>-0.961850</td>\n",
       "      <td>-0.961822</td>\n",
       "      <td>-0.961795</td>\n",
       "      <td>-0.961768</td>\n",
       "      <td>-0.961740</td>\n",
       "      <td>-0.961713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>-0.110581</td>\n",
       "      <td>-0.110680</td>\n",
       "      <td>-0.110780</td>\n",
       "      <td>-0.110879</td>\n",
       "      <td>-0.110978</td>\n",
       "      <td>-0.111078</td>\n",
       "      <td>-0.111177</td>\n",
       "      <td>-0.111276</td>\n",
       "      <td>-0.111376</td>\n",
       "      <td>-0.111475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119521</td>\n",
       "      <td>-0.119620</td>\n",
       "      <td>-0.119720</td>\n",
       "      <td>-0.119819</td>\n",
       "      <td>-0.119918</td>\n",
       "      <td>-0.120017</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>-0.120216</td>\n",
       "      <td>-0.120315</td>\n",
       "      <td>-0.120414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.774494</td>\n",
       "      <td>0.774557</td>\n",
       "      <td>0.774620</td>\n",
       "      <td>0.774684</td>\n",
       "      <td>0.774747</td>\n",
       "      <td>0.774810</td>\n",
       "      <td>0.774873</td>\n",
       "      <td>0.774937</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.775063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780156</td>\n",
       "      <td>0.780218</td>\n",
       "      <td>0.780281</td>\n",
       "      <td>0.780343</td>\n",
       "      <td>0.780406</td>\n",
       "      <td>0.780468</td>\n",
       "      <td>0.780531</td>\n",
       "      <td>0.780593</td>\n",
       "      <td>0.780656</td>\n",
       "      <td>0.780718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>-0.539301</td>\n",
       "      <td>-0.539386</td>\n",
       "      <td>-0.539470</td>\n",
       "      <td>-0.539554</td>\n",
       "      <td>-0.539638</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-0.539807</td>\n",
       "      <td>-0.539891</td>\n",
       "      <td>-0.539975</td>\n",
       "      <td>-0.540059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546859</td>\n",
       "      <td>-0.546942</td>\n",
       "      <td>-0.547026</td>\n",
       "      <td>-0.547110</td>\n",
       "      <td>-0.547193</td>\n",
       "      <td>-0.547277</td>\n",
       "      <td>-0.547361</td>\n",
       "      <td>-0.547444</td>\n",
       "      <td>-0.547528</td>\n",
       "      <td>-0.547612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>-0.999798</td>\n",
       "      <td>-0.999800</td>\n",
       "      <td>-0.999802</td>\n",
       "      <td>-0.999804</td>\n",
       "      <td>-0.999806</td>\n",
       "      <td>-0.999808</td>\n",
       "      <td>-0.999810</td>\n",
       "      <td>-0.999812</td>\n",
       "      <td>-0.999814</td>\n",
       "      <td>-0.999816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999939</td>\n",
       "      <td>-0.999940</td>\n",
       "      <td>-0.999941</td>\n",
       "      <td>-0.999942</td>\n",
       "      <td>-0.999943</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.999945</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>-0.999947</td>\n",
       "      <td>-0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.924872</td>\n",
       "      <td>0.924910</td>\n",
       "      <td>0.924948</td>\n",
       "      <td>0.924986</td>\n",
       "      <td>0.925024</td>\n",
       "      <td>0.925062</td>\n",
       "      <td>0.925100</td>\n",
       "      <td>0.925138</td>\n",
       "      <td>0.925176</td>\n",
       "      <td>0.925214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928257</td>\n",
       "      <td>0.928295</td>\n",
       "      <td>0.928332</td>\n",
       "      <td>0.928369</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>0.928443</td>\n",
       "      <td>0.928480</td>\n",
       "      <td>0.928518</td>\n",
       "      <td>0.928555</td>\n",
       "      <td>0.928592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>-0.674810</td>\n",
       "      <td>-0.674884</td>\n",
       "      <td>-0.674958</td>\n",
       "      <td>-0.675031</td>\n",
       "      <td>-0.675105</td>\n",
       "      <td>-0.675179</td>\n",
       "      <td>-0.675253</td>\n",
       "      <td>-0.675327</td>\n",
       "      <td>-0.675400</td>\n",
       "      <td>-0.675474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.681425</td>\n",
       "      <td>-0.681498</td>\n",
       "      <td>-0.681571</td>\n",
       "      <td>-0.681644</td>\n",
       "      <td>-0.681717</td>\n",
       "      <td>-0.681790</td>\n",
       "      <td>-0.681864</td>\n",
       "      <td>-0.681937</td>\n",
       "      <td>-0.682010</td>\n",
       "      <td>-0.682083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-0.247584</td>\n",
       "      <td>-0.247487</td>\n",
       "      <td>-0.247390</td>\n",
       "      <td>-0.247293</td>\n",
       "      <td>-0.247196</td>\n",
       "      <td>-0.247099</td>\n",
       "      <td>-0.247002</td>\n",
       "      <td>-0.246905</td>\n",
       "      <td>-0.246808</td>\n",
       "      <td>-0.246711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238854</td>\n",
       "      <td>-0.238757</td>\n",
       "      <td>-0.238660</td>\n",
       "      <td>-0.238562</td>\n",
       "      <td>-0.238465</td>\n",
       "      <td>-0.238368</td>\n",
       "      <td>-0.238271</td>\n",
       "      <td>-0.238174</td>\n",
       "      <td>-0.238077</td>\n",
       "      <td>-0.237980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-0.586868</td>\n",
       "      <td>-0.586787</td>\n",
       "      <td>-0.586706</td>\n",
       "      <td>-0.586625</td>\n",
       "      <td>-0.586544</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.586382</td>\n",
       "      <td>-0.586301</td>\n",
       "      <td>-0.586220</td>\n",
       "      <td>-0.586139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.579557</td>\n",
       "      <td>-0.579476</td>\n",
       "      <td>-0.579394</td>\n",
       "      <td>-0.579313</td>\n",
       "      <td>-0.579231</td>\n",
       "      <td>-0.579150</td>\n",
       "      <td>-0.579068</td>\n",
       "      <td>-0.578987</td>\n",
       "      <td>-0.578905</td>\n",
       "      <td>-0.578824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.735893</td>\n",
       "      <td>-0.735826</td>\n",
       "      <td>-0.735758</td>\n",
       "      <td>-0.735690</td>\n",
       "      <td>-0.735623</td>\n",
       "      <td>-0.735555</td>\n",
       "      <td>-0.735487</td>\n",
       "      <td>-0.735419</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>-0.735284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.729770</td>\n",
       "      <td>-0.729702</td>\n",
       "      <td>-0.729633</td>\n",
       "      <td>-0.729565</td>\n",
       "      <td>-0.729496</td>\n",
       "      <td>-0.729428</td>\n",
       "      <td>-0.729360</td>\n",
       "      <td>-0.729291</td>\n",
       "      <td>-0.729223</td>\n",
       "      <td>-0.729154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-0.310394</td>\n",
       "      <td>-0.310489</td>\n",
       "      <td>-0.310584</td>\n",
       "      <td>-0.310679</td>\n",
       "      <td>-0.310774</td>\n",
       "      <td>-0.310869</td>\n",
       "      <td>-0.310964</td>\n",
       "      <td>-0.311059</td>\n",
       "      <td>-0.311154</td>\n",
       "      <td>-0.311249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318937</td>\n",
       "      <td>-0.319031</td>\n",
       "      <td>-0.319126</td>\n",
       "      <td>-0.319221</td>\n",
       "      <td>-0.319316</td>\n",
       "      <td>-0.319411</td>\n",
       "      <td>-0.319505</td>\n",
       "      <td>-0.319600</td>\n",
       "      <td>-0.319695</td>\n",
       "      <td>-0.319790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.498355</td>\n",
       "      <td>0.498441</td>\n",
       "      <td>0.498528</td>\n",
       "      <td>0.498615</td>\n",
       "      <td>0.498701</td>\n",
       "      <td>0.498788</td>\n",
       "      <td>0.498875</td>\n",
       "      <td>0.498961</td>\n",
       "      <td>0.499048</td>\n",
       "      <td>0.499135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506137</td>\n",
       "      <td>0.506223</td>\n",
       "      <td>0.506310</td>\n",
       "      <td>0.506396</td>\n",
       "      <td>0.506482</td>\n",
       "      <td>0.506568</td>\n",
       "      <td>0.506655</td>\n",
       "      <td>0.506741</td>\n",
       "      <td>0.506827</td>\n",
       "      <td>0.506913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.978939</td>\n",
       "      <td>0.978960</td>\n",
       "      <td>0.978980</td>\n",
       "      <td>0.979001</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979041</td>\n",
       "      <td>0.979062</td>\n",
       "      <td>0.979082</td>\n",
       "      <td>0.979102</td>\n",
       "      <td>0.979123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980737</td>\n",
       "      <td>0.980757</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.980796</td>\n",
       "      <td>0.980815</td>\n",
       "      <td>0.980835</td>\n",
       "      <td>0.980854</td>\n",
       "      <td>0.980874</td>\n",
       "      <td>0.980893</td>\n",
       "      <td>0.980913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>-0.835920</td>\n",
       "      <td>-0.835975</td>\n",
       "      <td>-0.836030</td>\n",
       "      <td>-0.836085</td>\n",
       "      <td>-0.836140</td>\n",
       "      <td>-0.836195</td>\n",
       "      <td>-0.836249</td>\n",
       "      <td>-0.836304</td>\n",
       "      <td>-0.836359</td>\n",
       "      <td>-0.836414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.840826</td>\n",
       "      <td>-0.840880</td>\n",
       "      <td>-0.840934</td>\n",
       "      <td>-0.840988</td>\n",
       "      <td>-0.841042</td>\n",
       "      <td>-0.841097</td>\n",
       "      <td>-0.841151</td>\n",
       "      <td>-0.841205</td>\n",
       "      <td>-0.841259</td>\n",
       "      <td>-0.841313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>-0.414877</td>\n",
       "      <td>-0.414968</td>\n",
       "      <td>-0.415059</td>\n",
       "      <td>-0.415150</td>\n",
       "      <td>-0.415241</td>\n",
       "      <td>-0.415332</td>\n",
       "      <td>-0.415423</td>\n",
       "      <td>-0.415514</td>\n",
       "      <td>-0.415605</td>\n",
       "      <td>-0.415695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.423049</td>\n",
       "      <td>-0.423139</td>\n",
       "      <td>-0.423230</td>\n",
       "      <td>-0.423321</td>\n",
       "      <td>-0.423411</td>\n",
       "      <td>-0.423502</td>\n",
       "      <td>-0.423592</td>\n",
       "      <td>-0.423683</td>\n",
       "      <td>-0.423773</td>\n",
       "      <td>-0.423864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.340151</td>\n",
       "      <td>0.340057</td>\n",
       "      <td>0.339963</td>\n",
       "      <td>0.339869</td>\n",
       "      <td>0.339775</td>\n",
       "      <td>0.339681</td>\n",
       "      <td>0.339587</td>\n",
       "      <td>0.339493</td>\n",
       "      <td>0.339399</td>\n",
       "      <td>0.339305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331674</td>\n",
       "      <td>0.331580</td>\n",
       "      <td>0.331486</td>\n",
       "      <td>0.331391</td>\n",
       "      <td>0.331297</td>\n",
       "      <td>0.331203</td>\n",
       "      <td>0.331108</td>\n",
       "      <td>0.331014</td>\n",
       "      <td>0.330920</td>\n",
       "      <td>0.330825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>-0.850947</td>\n",
       "      <td>-0.850894</td>\n",
       "      <td>-0.850842</td>\n",
       "      <td>-0.850789</td>\n",
       "      <td>-0.850737</td>\n",
       "      <td>-0.850684</td>\n",
       "      <td>-0.850632</td>\n",
       "      <td>-0.850579</td>\n",
       "      <td>-0.850526</td>\n",
       "      <td>-0.850474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.846185</td>\n",
       "      <td>-0.846132</td>\n",
       "      <td>-0.846079</td>\n",
       "      <td>-0.846025</td>\n",
       "      <td>-0.845972</td>\n",
       "      <td>-0.845919</td>\n",
       "      <td>-0.845865</td>\n",
       "      <td>-0.845812</td>\n",
       "      <td>-0.845759</td>\n",
       "      <td>-0.845705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>-0.119734</td>\n",
       "      <td>-0.119833</td>\n",
       "      <td>-0.119933</td>\n",
       "      <td>-0.120032</td>\n",
       "      <td>-0.120131</td>\n",
       "      <td>-0.120230</td>\n",
       "      <td>-0.120330</td>\n",
       "      <td>-0.120429</td>\n",
       "      <td>-0.120528</td>\n",
       "      <td>-0.120628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128664</td>\n",
       "      <td>-0.128764</td>\n",
       "      <td>-0.128863</td>\n",
       "      <td>-0.128962</td>\n",
       "      <td>-0.129061</td>\n",
       "      <td>-0.129160</td>\n",
       "      <td>-0.129259</td>\n",
       "      <td>-0.129359</td>\n",
       "      <td>-0.129458</td>\n",
       "      <td>-0.129557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-0.310848</td>\n",
       "      <td>-0.310753</td>\n",
       "      <td>-0.310658</td>\n",
       "      <td>-0.310563</td>\n",
       "      <td>-0.310468</td>\n",
       "      <td>-0.310373</td>\n",
       "      <td>-0.310278</td>\n",
       "      <td>-0.310183</td>\n",
       "      <td>-0.310088</td>\n",
       "      <td>-0.309993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302282</td>\n",
       "      <td>-0.302186</td>\n",
       "      <td>-0.302091</td>\n",
       "      <td>-0.301996</td>\n",
       "      <td>-0.301900</td>\n",
       "      <td>-0.301805</td>\n",
       "      <td>-0.301710</td>\n",
       "      <td>-0.301614</td>\n",
       "      <td>-0.301519</td>\n",
       "      <td>-0.301424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.049772</td>\n",
       "      <td>0.049672</td>\n",
       "      <td>0.049572</td>\n",
       "      <td>0.049472</td>\n",
       "      <td>0.049373</td>\n",
       "      <td>0.049273</td>\n",
       "      <td>0.049173</td>\n",
       "      <td>0.049073</td>\n",
       "      <td>0.048973</td>\n",
       "      <td>0.048873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040781</td>\n",
       "      <td>0.040681</td>\n",
       "      <td>0.040582</td>\n",
       "      <td>0.040482</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>0.040282</td>\n",
       "      <td>0.040182</td>\n",
       "      <td>0.040082</td>\n",
       "      <td>0.039982</td>\n",
       "      <td>0.039882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>-0.898222</td>\n",
       "      <td>-0.898266</td>\n",
       "      <td>-0.898310</td>\n",
       "      <td>-0.898354</td>\n",
       "      <td>-0.898398</td>\n",
       "      <td>-0.898442</td>\n",
       "      <td>-0.898485</td>\n",
       "      <td>-0.898529</td>\n",
       "      <td>-0.898573</td>\n",
       "      <td>-0.898617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902141</td>\n",
       "      <td>-0.902185</td>\n",
       "      <td>-0.902228</td>\n",
       "      <td>-0.902271</td>\n",
       "      <td>-0.902314</td>\n",
       "      <td>-0.902357</td>\n",
       "      <td>-0.902400</td>\n",
       "      <td>-0.902443</td>\n",
       "      <td>-0.902486</td>\n",
       "      <td>-0.902529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.586295</td>\n",
       "      <td>0.586214</td>\n",
       "      <td>0.586133</td>\n",
       "      <td>0.586052</td>\n",
       "      <td>0.585971</td>\n",
       "      <td>0.585890</td>\n",
       "      <td>0.585809</td>\n",
       "      <td>0.585728</td>\n",
       "      <td>0.585647</td>\n",
       "      <td>0.585566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578981</td>\n",
       "      <td>0.578899</td>\n",
       "      <td>0.578818</td>\n",
       "      <td>0.578736</td>\n",
       "      <td>0.578654</td>\n",
       "      <td>0.578573</td>\n",
       "      <td>0.578491</td>\n",
       "      <td>0.578410</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>0.578247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.720201</td>\n",
       "      <td>0.720132</td>\n",
       "      <td>0.720063</td>\n",
       "      <td>0.719993</td>\n",
       "      <td>0.719924</td>\n",
       "      <td>0.719854</td>\n",
       "      <td>0.719785</td>\n",
       "      <td>0.719716</td>\n",
       "      <td>0.719646</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713928</td>\n",
       "      <td>0.713858</td>\n",
       "      <td>0.713788</td>\n",
       "      <td>0.713718</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.713578</td>\n",
       "      <td>0.713508</td>\n",
       "      <td>0.713438</td>\n",
       "      <td>0.713368</td>\n",
       "      <td>0.713298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.752538</td>\n",
       "      <td>-0.752604</td>\n",
       "      <td>-0.752670</td>\n",
       "      <td>-0.752735</td>\n",
       "      <td>-0.752801</td>\n",
       "      <td>-0.752867</td>\n",
       "      <td>-0.752933</td>\n",
       "      <td>-0.752999</td>\n",
       "      <td>-0.753064</td>\n",
       "      <td>-0.753130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758434</td>\n",
       "      <td>-0.758499</td>\n",
       "      <td>-0.758565</td>\n",
       "      <td>-0.758630</td>\n",
       "      <td>-0.758695</td>\n",
       "      <td>-0.758760</td>\n",
       "      <td>-0.758825</td>\n",
       "      <td>-0.758890</td>\n",
       "      <td>-0.758955</td>\n",
       "      <td>-0.759021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.986683</td>\n",
       "      <td>0.986699</td>\n",
       "      <td>0.986715</td>\n",
       "      <td>0.986732</td>\n",
       "      <td>0.986748</td>\n",
       "      <td>0.986764</td>\n",
       "      <td>0.986780</td>\n",
       "      <td>0.986797</td>\n",
       "      <td>0.986813</td>\n",
       "      <td>0.986829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988107</td>\n",
       "      <td>0.988122</td>\n",
       "      <td>0.988138</td>\n",
       "      <td>0.988153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>0.988184</td>\n",
       "      <td>0.988199</td>\n",
       "      <td>0.988214</td>\n",
       "      <td>0.988230</td>\n",
       "      <td>0.988245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.166203</td>\n",
       "      <td>0.166104</td>\n",
       "      <td>0.166006</td>\n",
       "      <td>0.165907</td>\n",
       "      <td>0.165809</td>\n",
       "      <td>0.165710</td>\n",
       "      <td>0.165611</td>\n",
       "      <td>0.165513</td>\n",
       "      <td>0.165414</td>\n",
       "      <td>0.165316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157322</td>\n",
       "      <td>0.157223</td>\n",
       "      <td>0.157124</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.156927</td>\n",
       "      <td>0.156828</td>\n",
       "      <td>0.156729</td>\n",
       "      <td>0.156630</td>\n",
       "      <td>0.156532</td>\n",
       "      <td>0.156433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.403353</td>\n",
       "      <td>0.403261</td>\n",
       "      <td>0.403170</td>\n",
       "      <td>0.403078</td>\n",
       "      <td>0.402987</td>\n",
       "      <td>0.402895</td>\n",
       "      <td>0.402804</td>\n",
       "      <td>0.402712</td>\n",
       "      <td>0.402621</td>\n",
       "      <td>0.402529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395101</td>\n",
       "      <td>0.395009</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.394826</td>\n",
       "      <td>0.394734</td>\n",
       "      <td>0.394642</td>\n",
       "      <td>0.394550</td>\n",
       "      <td>0.394458</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>0.394274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.032609  0.032709  0.032809  0.032909  0.033009  0.033109  0.033209   \n",
       "1   -0.813930 -0.813872 -0.813814 -0.813756 -0.813698 -0.813640 -0.813581   \n",
       "2    0.082683  0.082584  0.082484  0.082384  0.082285  0.082185  0.082085   \n",
       "3   -0.932512 -0.932548 -0.932584 -0.932620 -0.932656 -0.932692 -0.932729   \n",
       "4    0.996140  0.996148  0.996157  0.996166  0.996175  0.996183  0.996192   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.720201  0.720132  0.720063  0.719993  0.719924  0.719854  0.719785   \n",
       "996 -0.752538 -0.752604 -0.752670 -0.752735 -0.752801 -0.752867 -0.752933   \n",
       "997  0.986683  0.986699  0.986715  0.986732  0.986748  0.986764  0.986780   \n",
       "998  0.166203  0.166104  0.166006  0.165907  0.165809  0.165710  0.165611   \n",
       "999  0.403353  0.403261  0.403170  0.403078  0.402987  0.402895  0.402804   \n",
       "\n",
       "           7         8         9   ...        90        91        92  \\\n",
       "0    0.033309  0.033408  0.033508  ...  0.041603  0.041703  0.041803   \n",
       "1   -0.813523 -0.813465 -0.813407  ... -0.808669 -0.808610 -0.808551   \n",
       "2    0.081986  0.081886  0.081787  ...  0.073711  0.073611  0.073512   \n",
       "3   -0.932765 -0.932801 -0.932837  ... -0.935724 -0.935760 -0.935795   \n",
       "4    0.996201  0.996210  0.996218  ...  0.996889  0.996897  0.996905   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.719716  0.719646  0.719577  ...  0.713928  0.713858  0.713788   \n",
       "996 -0.752999 -0.753064 -0.753130  ... -0.758434 -0.758499 -0.758565   \n",
       "997  0.986797  0.986813  0.986829  ...  0.988107  0.988122  0.988138   \n",
       "998  0.165513  0.165414  0.165316  ...  0.157322  0.157223  0.157124   \n",
       "999  0.402712  0.402621  0.402529  ...  0.395101  0.395009  0.394917   \n",
       "\n",
       "           93        94        95        96        97        98        99  \n",
       "0    0.041902  0.042002  0.042102  0.042202  0.042302  0.042402  0.042502  \n",
       "1   -0.808492 -0.808433 -0.808374 -0.808315 -0.808257 -0.808198 -0.808139  \n",
       "2    0.073412  0.073312  0.073212  0.073113  0.073013  0.072913  0.072813  \n",
       "3   -0.935830 -0.935865 -0.935901 -0.935936 -0.935971 -0.936006 -0.936042  \n",
       "4    0.996913  0.996921  0.996929  0.996936  0.996944  0.996952  0.996960  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  0.713718  0.713648  0.713578  0.713508  0.713438  0.713368  0.713298  \n",
       "996 -0.758630 -0.758695 -0.758760 -0.758825 -0.758890 -0.758955 -0.759021  \n",
       "997  0.988153  0.988168  0.988184  0.988199  0.988214  0.988230  0.988245  \n",
       "998  0.157025  0.156927  0.156828  0.156729  0.156630  0.156532  0.156433  \n",
       "999  0.394826  0.394734  0.394642  0.394550  0.394458  0.394366  0.394274  \n",
       "\n",
       "[1000 rows x 100 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array(sines))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_samples = df.iloc[:,0:99]\n",
    "Y2_samples = df.iloc[:,99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X2_samples_scale = min_max_scaler.fit_transform(X2_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X2_train, X2_val_and_test, Y2_train, Y2_val_and_test = train_test_split(X2_samples_scale, Y2_samples, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_val, X2_test, Y2_val, Y2_test = train_test_split(X2_val_and_test, Y2_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 99) (150, 99) (150, 99) (700,) (150,) (150,)\n"
     ]
    }
   ],
   "source": [
    "print(X2_train.shape, X2_val.shape, X2_test.shape, Y2_train.shape, Y2_val.shape, Y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 0s 497us/step - loss: 0.6596 - acc: 0.0000e+00 - val_loss: 0.6358 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s 77us/step - loss: 0.6044 - acc: 0.0000e+00 - val_loss: 0.5889 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s 69us/step - loss: 0.5523 - acc: 0.0000e+00 - val_loss: 0.5429 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s 68us/step - loss: 0.4491 - acc: 0.0000e+00 - val_loss: 0.4520 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s 49us/step - loss: 0.3974 - acc: 0.0000e+00 - val_loss: 0.4069 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.3453 - acc: 0.0000e+00 - val_loss: 0.3602 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s 61us/step - loss: 0.2916 - acc: 0.0000e+00 - val_loss: 0.3140 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s 61us/step - loss: 0.2369 - acc: 0.0000e+00 - val_loss: 0.2625 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: 0.1782 - acc: 0.0000e+00 - val_loss: 0.2110 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: 0.1171 - acc: 0.0000e+00 - val_loss: 0.1549 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 0.0525 - acc: 0.0000e+00 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s 72us/step - loss: -0.0163 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s 60us/step - loss: -0.0927 - acc: 0.0000e+00 - val_loss: -0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s 63us/step - loss: -0.1735 - acc: 0.0000e+00 - val_loss: -0.1099 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s 74us/step - loss: -0.2605 - acc: 0.0000e+00 - val_loss: -0.1884 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s 58us/step - loss: -0.3558 - acc: 0.0000e+00 - val_loss: -0.2752 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s 73us/step - loss: -0.4628 - acc: 0.0000e+00 - val_loss: -0.3727 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s 75us/step - loss: -0.5827 - acc: 0.0000e+00 - val_loss: -0.4834 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s 73us/step - loss: -0.7193 - acc: 0.0000e+00 - val_loss: -0.6094 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: -0.8766 - acc: 0.0000e+00 - val_loss: -0.7566 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: -1.0634 - acc: 0.0000e+00 - val_loss: -0.9267 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s 60us/step - loss: -1.2848 - acc: 0.0000e+00 - val_loss: -1.1371 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s 65us/step - loss: -1.5579 - acc: 0.0000e+00 - val_loss: -1.3896 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s 63us/step - loss: -1.9041 - acc: 0.0000e+00 - val_loss: -1.7088 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s 55us/step - loss: -2.3482 - acc: 0.0000e+00 - val_loss: -2.1570 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s 70us/step - loss: -2.7857 - acc: 0.0000e+00 - val_loss: -2.3251 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s 73us/step - loss: -2.8825 - acc: 0.0000e+00 - val_loss: -2.3945 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s 72us/step - loss: -2.9150 - acc: 0.0000e+00 - val_loss: -2.3941 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s 70us/step - loss: -2.9374 - acc: 0.0000e+00 - val_loss: -2.4029 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s 68us/step - loss: -2.9493 - acc: 0.0000e+00 - val_loss: -2.4109 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s 55us/step - loss: -2.9596 - acc: 0.0000e+00 - val_loss: -2.4400 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: -2.9714 - acc: 0.0000e+00 - val_loss: -2.4572 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s 68us/step - loss: -2.9787 - acc: 0.0000e+00 - val_loss: -2.4557 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s 65us/step - loss: -2.9849 - acc: 0.0000e+00 - val_loss: -2.4651 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s 52us/step - loss: -2.9901 - acc: 0.0000e+00 - val_loss: -2.4622 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s 55us/step - loss: -2.9938 - acc: 0.0000e+00 - val_loss: -2.4761 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s 74us/step - loss: -2.9931 - acc: 0.0000e+00 - val_loss: -2.4803 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: -2.9947 - acc: 0.0000e+00 - val_loss: -2.4801 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s 55us/step - loss: -2.9973 - acc: 0.0000e+00 - val_loss: -2.4466 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s 66us/step - loss: -3.0023 - acc: 0.0000e+00 - val_loss: -2.4862 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s 56us/step - loss: -3.0007 - acc: 0.0000e+00 - val_loss: -2.4851 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s 56us/step - loss: -3.0036 - acc: 0.0000e+00 - val_loss: -2.4865 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s 59us/step - loss: -3.0090 - acc: 0.0000e+00 - val_loss: -2.4746 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s 67us/step - loss: -3.0223 - acc: 0.0000e+00 - val_loss: -2.5019 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s 69us/step - loss: -3.0242 - acc: 0.0000e+00 - val_loss: -2.5031 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s 67us/step - loss: -3.0267 - acc: 0.0000e+00 - val_loss: -2.5103 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: -3.0261 - acc: 0.0000e+00 - val_loss: -2.5109 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s 49us/step - loss: -3.0304 - acc: 0.0000e+00 - val_loss: -2.5137 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s 52us/step - loss: -3.0310 - acc: 0.0000e+00 - val_loss: -2.5147 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: -3.0300 - acc: 0.0000e+00 - val_loss: -2.5105 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: -3.0333 - acc: 0.0000e+00 - val_loss: -2.4944 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s 45us/step - loss: -3.0324 - acc: 0.0000e+00 - val_loss: -2.5010 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: -3.0341 - acc: 0.0000e+00 - val_loss: -2.5171 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: -3.0335 - acc: 0.0000e+00 - val_loss: -2.5068 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: -3.0369 - acc: 0.0000e+00 - val_loss: -2.5161 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: -3.0377 - acc: 0.0000e+00 - val_loss: -2.5171 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: -3.0379 - acc: 0.0000e+00 - val_loss: -2.5179 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: -3.0366 - acc: 0.0000e+00 - val_loss: -2.5215 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: -3.0378 - acc: 0.0000e+00 - val_loss: -2.4956 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: -3.0420 - acc: 0.0000e+00 - val_loss: -2.5188 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: -3.0411 - acc: 0.0000e+00 - val_loss: -2.5206 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: -3.0400 - acc: 0.0000e+00 - val_loss: -2.5139 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s 55us/step - loss: -3.0427 - acc: 0.0000e+00 - val_loss: -2.5224 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: -3.0426 - acc: 0.0000e+00 - val_loss: -2.5152 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: -3.0430 - acc: 0.0000e+00 - val_loss: -2.5224 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: -3.0446 - acc: 0.0000e+00 - val_loss: -2.5215 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: -3.0428 - acc: 0.0000e+00 - val_loss: -2.5223 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: -3.0445 - acc: 0.0000e+00 - val_loss: -2.5242 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: -3.0462 - acc: 0.0000e+00 - val_loss: -2.5257 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: -3.0437 - acc: 0.0000e+00 - val_loss: -2.5238 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: -3.0435 - acc: 0.0000e+00 - val_loss: -2.5146 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: -3.0470 - acc: 0.0000e+00 - val_loss: -2.5187 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s 49us/step - loss: -3.0447 - acc: 0.0000e+00 - val_loss: -2.5264 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s 59us/step - loss: -3.0441 - acc: 0.0000e+00 - val_loss: -2.5222 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: -3.0490 - acc: 0.0000e+00 - val_loss: -2.5224 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s 45us/step - loss: -3.0474 - acc: 0.0000e+00 - val_loss: -2.5270 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: -3.0502 - acc: 0.0000e+00 - val_loss: -2.5206 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: -3.0503 - acc: 0.0000e+00 - val_loss: -2.5273 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: -3.0491 - acc: 0.0000e+00 - val_loss: -2.5229 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: -3.0497 - acc: 0.0000e+00 - val_loss: -2.5285 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: -3.0498 - acc: 0.0000e+00 - val_loss: -2.5311 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: -3.0514 - acc: 0.0000e+00 - val_loss: -2.5228 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: -3.0527 - acc: 0.0000e+00 - val_loss: -2.5288 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: -3.0545 - acc: 0.0000e+00 - val_loss: -2.5270 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: -3.0544 - acc: 0.0000e+00 - val_loss: -2.5229 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s 52us/step - loss: -3.0533 - acc: 0.0000e+00 - val_loss: -2.5223 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s 42us/step - loss: -3.0544 - acc: 0.0000e+00 - val_loss: -2.5258 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s 49us/step - loss: -3.0547 - acc: 0.0000e+00 - val_loss: -2.5343 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s 49us/step - loss: -3.0555 - acc: 0.0000e+00 - val_loss: -2.5345 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: -3.0536 - acc: 0.0000e+00 - val_loss: -2.5315 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s 53us/step - loss: -3.0563 - acc: 0.0000e+00 - val_loss: -2.5263 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 0s 52us/step - loss: -3.0566 - acc: 0.0000e+00 - val_loss: -2.5348 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s 49us/step - loss: -3.0557 - acc: 0.0000e+00 - val_loss: -2.5348 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: -3.0586 - acc: 0.0000e+00 - val_loss: -2.5346 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 42us/step - loss: -3.0557 - acc: 0.0000e+00 - val_loss: -2.5363 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 45us/step - loss: -3.0582 - acc: 0.0000e+00 - val_loss: -2.5368 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: -3.0583 - acc: 0.0000e+00 - val_loss: -2.5381 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: -3.0589 - acc: 0.0000e+00 - val_loss: -2.5394 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: -3.0593 - acc: 0.0000e+00 - val_loss: -2.5391 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(99,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X2_train, Y2_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X2_val, Y2_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 117us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X2_test, Y2_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.6292 - acc: 0.0000e+00 - val_loss: 0.5568 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -1.2208 - acc: 0.0000e+00 - val_loss: -1.4875 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -1.7852 - acc: 0.0000e+00 - val_loss: -1.2273 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.3947 - acc: 0.0000e+00 - val_loss: -2.5781 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0935 - acc: 0.0000e+00 - val_loss: -2.5981 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0933 - acc: 0.0000e+00 - val_loss: -2.5870 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1012 - acc: 0.0000e+00 - val_loss: -2.5918 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1112 - acc: 0.0000e+00 - val_loss: -2.5989 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1047 - acc: 0.0000e+00 - val_loss: -2.5962 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0960 - acc: 0.0000e+00 - val_loss: -2.5814 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1102 - acc: 0.0000e+00 - val_loss: -2.5693 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1070 - acc: 0.0000e+00 - val_loss: -2.5624 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0900 - acc: 0.0000e+00 - val_loss: -2.6040 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0548 - acc: 0.0000e+00 - val_loss: -2.5946 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0935 - acc: 0.0000e+00 - val_loss: -2.6039 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1182 - acc: 0.0000e+00 - val_loss: -2.6066 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1159 - acc: 0.0000e+00 - val_loss: -2.6085 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1177 - acc: 0.0000e+00 - val_loss: -2.6097 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1226 - acc: 0.0000e+00 - val_loss: -2.6050 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1216 - acc: 0.0000e+00 - val_loss: -2.6085 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1184 - acc: 0.0000e+00 - val_loss: -2.6101 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1115 - acc: 0.0000e+00 - val_loss: -2.5851 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1160 - acc: 0.0000e+00 - val_loss: -2.6036 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1191 - acc: 0.0000e+00 - val_loss: -2.6101 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1191 - acc: 0.0000e+00 - val_loss: -2.6062 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1176 - acc: 0.0000e+00 - val_loss: -2.6071 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1232 - acc: 0.0000e+00 - val_loss: -2.6066 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1212 - acc: 0.0000e+00 - val_loss: -2.6067 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1220 - acc: 0.0000e+00 - val_loss: -2.6076 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1153 - acc: 0.0000e+00 - val_loss: -2.6005 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -3.1176 - acc: 0.0000e+00 - val_loss: -2.6035 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1232 - acc: 0.0000e+00 - val_loss: -2.6118 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1163 - acc: 0.0000e+00 - val_loss: -2.6026 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1225 - acc: 0.0000e+00 - val_loss: -2.6108 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1206 - acc: 0.0000e+00 - val_loss: -2.6021 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1049 - acc: 0.0000e+00 - val_loss: -2.6064 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1144 - acc: 0.0000e+00 - val_loss: -2.6099 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -3.1198 - acc: 0.0000e+00 - val_loss: -2.6107 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1095 - acc: 0.0000e+00 - val_loss: -2.5691 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0727 - acc: 0.0000e+00 - val_loss: -2.5800 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0624 - acc: 0.0000e+00 - val_loss: -2.5843 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0901 - acc: 0.0000e+00 - val_loss: -2.6018 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1144 - acc: 0.0000e+00 - val_loss: -2.5756 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0999 - acc: 0.0000e+00 - val_loss: -2.6025 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1102 - acc: 0.0000e+00 - val_loss: -2.5996 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0352 - acc: 0.0000e+00 - val_loss: -2.3564 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0068 - acc: 0.0000e+00 - val_loss: -2.5756 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -3.1047 - acc: 0.0000e+00 - val_loss: -2.6055 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1164 - acc: 0.0000e+00 - val_loss: -2.6091 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1151 - acc: 0.0000e+00 - val_loss: -2.5719 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1042 - acc: 0.0000e+00 - val_loss: -2.6085 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1210 - acc: 0.0000e+00 - val_loss: -2.6073 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1221 - acc: 0.0000e+00 - val_loss: -2.6086 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1253 - acc: 0.0000e+00 - val_loss: -2.6122 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1219 - acc: 0.0000e+00 - val_loss: -2.6102 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -3.1202 - acc: 0.0000e+00 - val_loss: -2.6004 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -3.1221 - acc: 0.0000e+00 - val_loss: -2.6123 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1265 - acc: 0.0000e+00 - val_loss: -2.6056 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1253 - acc: 0.0000e+00 - val_loss: -2.5849 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0917 - acc: 0.0000e+00 - val_loss: -2.5943 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -3.0908 - acc: 0.0000e+00 - val_loss: -2.5626 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -3.1037 - acc: 0.0000e+00 - val_loss: -2.6083 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1244 - acc: 0.0000e+00 - val_loss: -2.6114 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1262 - acc: 0.0000e+00 - val_loss: -2.6123 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1246 - acc: 0.0000e+00 - val_loss: -2.6128 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1245 - acc: 0.0000e+00 - val_loss: -2.6128 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -3.1263 - acc: 0.0000e+00 - val_loss: -2.6129 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1266 - acc: 0.0000e+00 - val_loss: -2.6132 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1262 - acc: 0.0000e+00 - val_loss: -2.6088 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1230 - acc: 0.0000e+00 - val_loss: -2.5881 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1138 - acc: 0.0000e+00 - val_loss: -2.5904 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1153 - acc: 0.0000e+00 - val_loss: -2.5966 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1220 - acc: 0.0000e+00 - val_loss: -2.6074 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1261 - acc: 0.0000e+00 - val_loss: -2.6133 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1260 - acc: 0.0000e+00 - val_loss: -2.6104 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1266 - acc: 0.0000e+00 - val_loss: -2.6129 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1269 - acc: 0.0000e+00 - val_loss: -2.6117 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1269 - acc: 0.0000e+00 - val_loss: -2.6131 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1189 - acc: 0.0000e+00 - val_loss: -2.6124 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1182 - acc: 0.0000e+00 - val_loss: -2.6125 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1269 - acc: 0.0000e+00 - val_loss: -2.6079 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1259 - acc: 0.0000e+00 - val_loss: -2.5830 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0873 - acc: 0.0000e+00 - val_loss: -2.5368 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0798 - acc: 0.0000e+00 - val_loss: -2.5949 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1171 - acc: 0.0000e+00 - val_loss: -2.6115 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1252 - acc: 0.0000e+00 - val_loss: -2.6125 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1260 - acc: 0.0000e+00 - val_loss: -2.6091 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1159 - acc: 0.0000e+00 - val_loss: -2.5857 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1227 - acc: 0.0000e+00 - val_loss: -2.6132 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1270 - acc: 0.0000e+00 - val_loss: -2.6129 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1268 - acc: 0.0000e+00 - val_loss: -2.6111 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1240 - acc: 0.0000e+00 - val_loss: -2.6011 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1199 - acc: 0.0000e+00 - val_loss: -2.6000 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1122 - acc: 0.0000e+00 - val_loss: -2.5941 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1204 - acc: 0.0000e+00 - val_loss: -2.6112 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1250 - acc: 0.0000e+00 - val_loss: -2.6122 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1256 - acc: 0.0000e+00 - val_loss: -2.6129 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1246 - acc: 0.0000e+00 - val_loss: -2.6061 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.1236 - acc: 0.0000e+00 - val_loss: -2.5914 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -3.0841 - acc: 0.0000e+00 - val_loss: -2.6040 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential([\n",
    "    Dense(1000, activation='relu', input_shape=(99,)),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist_2 = model_2.fit(X2_train, Y2_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X2_val, Y2_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_2.history['loss'])\n",
    "plt.plot(hist_2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 20.4922 - acc: 0.0000e+00 - val_loss: 10.0708 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 4.7905 - acc: 0.0000e+00 - val_loss: 1.3798 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -0.5789 - acc: 0.0000e+00 - val_loss: -0.9993 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -1.7753 - acc: 0.0000e+00 - val_loss: -1.5399 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.1475 - acc: 0.0000e+00 - val_loss: -1.7171 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.3147 - acc: 0.0000e+00 - val_loss: -1.7778 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.3585 - acc: 0.0000e+00 - val_loss: -1.9492 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.4682 - acc: 0.0000e+00 - val_loss: -2.0297 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.5328 - acc: 0.0000e+00 - val_loss: -2.0474 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.5764 - acc: 0.0000e+00 - val_loss: -2.0973 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.6027 - acc: 0.0000e+00 - val_loss: -2.1245 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.6359 - acc: 0.0000e+00 - val_loss: -2.1582 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.6413 - acc: 0.0000e+00 - val_loss: -2.0906 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.6631 - acc: 0.0000e+00 - val_loss: -2.1807 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.6955 - acc: 0.0000e+00 - val_loss: -2.1537 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.6946 - acc: 0.0000e+00 - val_loss: -2.2147 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.7140 - acc: 0.0000e+00 - val_loss: -2.2094 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.7404 - acc: 0.0000e+00 - val_loss: -2.2473 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.7518 - acc: 0.0000e+00 - val_loss: -2.2567 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.7636 - acc: 0.0000e+00 - val_loss: -2.2727 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.7756 - acc: 0.0000e+00 - val_loss: -2.2822 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.7912 - acc: 0.0000e+00 - val_loss: -2.2942 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.7928 - acc: 0.0000e+00 - val_loss: -2.3009 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.8022 - acc: 0.0000e+00 - val_loss: -2.3129 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8048 - acc: 0.0000e+00 - val_loss: -2.2756 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8149 - acc: 0.0000e+00 - val_loss: -2.3129 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8137 - acc: 0.0000e+00 - val_loss: -2.3318 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8328 - acc: 0.0000e+00 - val_loss: -2.3357 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8390 - acc: 0.0000e+00 - val_loss: -2.3385 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8381 - acc: 0.0000e+00 - val_loss: -2.3391 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8519 - acc: 0.0000e+00 - val_loss: -2.3297 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8525 - acc: 0.0000e+00 - val_loss: -2.3624 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8617 - acc: 0.0000e+00 - val_loss: -2.3673 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8507 - acc: 0.0000e+00 - val_loss: -2.3376 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8596 - acc: 0.0000e+00 - val_loss: -2.3441 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8424 - acc: 0.0000e+00 - val_loss: -2.3345 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8506 - acc: 0.0000e+00 - val_loss: -2.3687 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8645 - acc: 0.0000e+00 - val_loss: -2.3702 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8712 - acc: 0.0000e+00 - val_loss: -2.3801 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8878 - acc: 0.0000e+00 - val_loss: -2.3892 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8814 - acc: 0.0000e+00 - val_loss: -2.3484 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8696 - acc: 0.0000e+00 - val_loss: -2.3311 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8602 - acc: 0.0000e+00 - val_loss: -2.3490 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8813 - acc: 0.0000e+00 - val_loss: -2.3930 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: -2.8987 - acc: 0.0000e+00 - val_loss: -2.3892 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: -2.8944 - acc: 0.0000e+00 - val_loss: -2.3956 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: -2.9027 - acc: 0.0000e+00 - val_loss: -2.3783 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: -2.9068 - acc: 0.0000e+00 - val_loss: -2.4025 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9028 - acc: 0.0000e+00 - val_loss: -2.3964 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8962 - acc: 0.0000e+00 - val_loss: -2.3720 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.8905 - acc: 0.0000e+00 - val_loss: -2.4090 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9083 - acc: 0.0000e+00 - val_loss: -2.3849 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9143 - acc: 0.0000e+00 - val_loss: -2.4182 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9134 - acc: 0.0000e+00 - val_loss: -2.4125 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9144 - acc: 0.0000e+00 - val_loss: -2.3822 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9127 - acc: 0.0000e+00 - val_loss: -2.4122 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9129 - acc: 0.0000e+00 - val_loss: -2.4156 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9243 - acc: 0.0000e+00 - val_loss: -2.4251 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9159 - acc: 0.0000e+00 - val_loss: -2.4215 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9220 - acc: 0.0000e+00 - val_loss: -2.4057 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9253 - acc: 0.0000e+00 - val_loss: -2.4268 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9228 - acc: 0.0000e+00 - val_loss: -2.4229 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9164 - acc: 0.0000e+00 - val_loss: -2.3973 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9061 - acc: 0.0000e+00 - val_loss: -2.3970 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9016 - acc: 0.0000e+00 - val_loss: -2.3524 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.8687 - acc: 0.0000e+00 - val_loss: -2.4200 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9114 - acc: 0.0000e+00 - val_loss: -2.4231 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9151 - acc: 0.0000e+00 - val_loss: -2.4038 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9223 - acc: 0.0000e+00 - val_loss: -2.4159 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9164 - acc: 0.0000e+00 - val_loss: -2.4338 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9250 - acc: 0.0000e+00 - val_loss: -2.4326 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9318 - acc: 0.0000e+00 - val_loss: -2.4206 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9167 - acc: 0.0000e+00 - val_loss: -2.4074 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9159 - acc: 0.0000e+00 - val_loss: -2.4191 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9176 - acc: 0.0000e+00 - val_loss: -2.4327 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9102 - acc: 0.0000e+00 - val_loss: -2.4049 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9174 - acc: 0.0000e+00 - val_loss: -2.4277 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9224 - acc: 0.0000e+00 - val_loss: -2.4320 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9229 - acc: 0.0000e+00 - val_loss: -2.4245 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9266 - acc: 0.0000e+00 - val_loss: -2.4131 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9283 - acc: 0.0000e+00 - val_loss: -2.4138 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9276 - acc: 0.0000e+00 - val_loss: -2.4326 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9310 - acc: 0.0000e+00 - val_loss: -2.4364 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9428 - acc: 0.0000e+00 - val_loss: -2.4443 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9377 - acc: 0.0000e+00 - val_loss: -2.4101 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9301 - acc: 0.0000e+00 - val_loss: -2.4356 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9431 - acc: 0.0000e+00 - val_loss: -2.4454 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9360 - acc: 0.0000e+00 - val_loss: -2.4247 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9180 - acc: 0.0000e+00 - val_loss: -2.4045 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9164 - acc: 0.0000e+00 - val_loss: -2.4161 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9246 - acc: 0.0000e+00 - val_loss: -2.4326 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9142 - acc: 0.0000e+00 - val_loss: -2.3952 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9065 - acc: 0.0000e+00 - val_loss: -2.4172 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9276 - acc: 0.0000e+00 - val_loss: -2.4324 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9366 - acc: 0.0000e+00 - val_loss: -2.4335 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9301 - acc: 0.0000e+00 - val_loss: -2.4295 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9329 - acc: 0.0000e+00 - val_loss: -2.4256 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9291 - acc: 0.0000e+00 - val_loss: -2.4314 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 1s 1ms/step - loss: -2.9012 - acc: 0.0000e+00 - val_loss: -2.4040 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: -2.9279 - acc: 0.0000e+00 - val_loss: -2.4097 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model_3 = Sequential([\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(99,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)),\n",
    "])\n",
    "\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist_3 = model_3.fit(X2_train, Y2_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X2_val, Y2_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_3.history['loss'])\n",
    "plt.plot(hist_3.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.ylim(top=1.2, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_3.history['acc'])\n",
    "plt.plot(hist_3.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
